{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this guide, we'll implement linear regression from scratch using gradient descent. Starting with dataset loading, we'll cover the mathematical foundations and step-by-step code implementation.\n",
    "\n",
    "The goal is to understand how linear regression works, how gradient descent optimizes model parameters, and how to build it without high-level machine learning libraries.\n",
    "\n",
    "Table of Contents\n",
    "Importing Libraries\n",
    "Setting up the necessary libraries for data manipulation, model implementation, and visualization.\n",
    "\n",
    "Loading and Exploring the Dataset\n",
    "Understanding the structure of the dataset and initial data exploration.\n",
    "\n",
    "Preparing the Data\n",
    "Preprocessing the data by scaling features and splitting into training and testing sets.\n",
    "\n",
    "Initializing Parameters\n",
    "Defining the initial parameters for the model, including weights and bias.\n",
    "\n",
    "Defining the Prediction Function\n",
    "Implementing the model's prediction function to make estimates based on input data.\n",
    "\n",
    "Defining the Cost Function\n",
    "Formulating the cost function to measure the accuracy of predictions against actual values.\n",
    "\n",
    "Computing the Gradients\n",
    "Calculating the gradients for weights and bias to optimize the cost function.\n",
    "\n",
    "Updating Parameters Using Gradient Descent\n",
    "Applying gradient descent to adjust parameters and minimize the cost function.\n",
    "\n",
    "Training the Model\n",
    "Training the model using the data and updating parameters through iterative optimization.\n",
    "\n",
    "Evaluating Model Performance with Test Data\n",
    "Assessing the model's performance using test data and relevant metrics.\n",
    "\n",
    "Conclusion\n",
    "Summarizing the key findings and insights from the model implementation.\n",
    "\n",
    "Comparison with Sklearn Linear Regression\n",
    "Side by side comparison of the algorithm that we've written with the algorithms predefined in sklearn to check performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Importing Libraries\n",
    "\n",
    "The following code imports essential libraries for linear regression and dataset loading:\n",
    "\n",
    "numpy: For numerical computing and array manipulation.\n",
    "\n",
    "load_diabetes: Loads the Diabetes dataset for regression tasks.\n",
    "\n",
    "matplotlib.pyplot: For visualizations such as loss curves and predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp313-cp313-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\abhay jha\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (2.1.2)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.2-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp313-cp313-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.1 MB 2.7 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.3/11.1 MB 3.4 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.1/11.1 MB 3.4 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 2.9/11.1 MB 3.3 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.7/11.1 MB 3.6 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 4.7/11.1 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.5/11.1 MB 3.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.8/11.1 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.3/11.1 MB 3.3 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 6.8/11.1 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.1/11.1 MB 3.1 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 7.6/11.1 MB 3.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.1/11.1 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.7/11.1 MB 2.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.9/11.1 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.4/11.1 MB 2.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.7/11.1 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.2/11.1 MB 2.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.7/11.1 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 2.7 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.15.2-cp313-cp313-win_amd64.whl (41.0 MB)\n",
      "   ---------------------------------------- 0.0/41.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.8/41.0 MB 5.0 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 1.8/41.0 MB 4.6 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 3.1/41.0 MB 4.9 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 3.9/41.0 MB 4.9 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 5.0/41.0 MB 4.8 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 6.0/41.0 MB 4.8 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 6.8/41.0 MB 4.6 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 7.9/41.0 MB 4.5 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 8.7/41.0 MB 4.5 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 9.7/41.0 MB 4.5 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 10.2/41.0 MB 4.5 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 11.0/41.0 MB 4.3 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 11.5/41.0 MB 4.2 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 12.1/41.0 MB 4.1 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 13.1/41.0 MB 4.1 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 13.9/41.0 MB 4.1 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 14.9/41.0 MB 4.1 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 15.7/41.0 MB 4.1 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 16.8/41.0 MB 4.1 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 17.8/41.0 MB 4.2 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 18.9/41.0 MB 4.2 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 19.9/41.0 MB 4.3 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 20.7/41.0 MB 4.2 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 21.8/41.0 MB 4.3 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 22.5/41.0 MB 4.3 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 23.3/41.0 MB 4.2 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 24.1/41.0 MB 4.2 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 24.6/41.0 MB 4.2 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 25.2/41.0 MB 4.1 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 25.4/41.0 MB 4.0 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 26.0/41.0 MB 3.9 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 26.2/41.0 MB 3.9 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 26.7/41.0 MB 3.9 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 27.3/41.0 MB 3.8 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 27.5/41.0 MB 3.7 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 28.0/41.0 MB 3.7 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 28.6/41.0 MB 3.7 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 29.1/41.0 MB 3.6 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 29.9/41.0 MB 3.6 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 30.7/41.0 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 31.2/41.0 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 31.5/41.0 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 32.0/41.0 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 32.8/41.0 MB 3.5 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 33.0/41.0 MB 3.5 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 34.1/41.0 MB 3.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 34.6/41.0 MB 3.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 34.9/41.0 MB 3.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 35.4/41.0 MB 3.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 35.7/41.0 MB 3.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 36.2/41.0 MB 3.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 37.0/41.0 MB 3.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 37.7/41.0 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 38.3/41.0 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 38.8/41.0 MB 3.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 39.6/41.0 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.1/41.0 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 41.0/41.0 MB 3.3 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\abhay jha\\\\AppData\\\\Roaming\\\\Python\\\\Python313\\\\site-packages\\\\sklearn\\\\.libs\\\\msvcp140.dll'\n",
      "Check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ** 2. Loading and Exploring the Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code loads the Diabetes dataset and prints:\n",
    "\n",
    "X: Feature matrix (442 samples, 10 features).\n",
    "y: Target vector (442 values, diabetes progression).\n",
    "It also displays the feature names, the first five samples of X, and the first five target values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names: ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n",
      "First five target values: [151.  75. 141. 206. 135.]\n"
     ]
    }
   ],
   "source": [
    "data = load_diabetes()\n",
    "\n",
    "X = data.data         # Feature matrix (shape: [442, 10])\n",
    "y = data.target       # Target vector (shape: [442,])\n",
    "\n",
    "print('Feature names:', data.feature_names)\n",
    "print('First five target values:', y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Preparing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code standardizes the features and splits the dataset into training and testing sets:\n",
    "\n",
    "StandardScaler: Standardizes the feature matrix by removing the mean and scaling to unit variance.\n",
    "\n",
    "train_test_split: Splits the dataset into training (80%) and testing (20%) sets.\n",
    "\n",
    "The feature matrix X is transformed, and the dataset is divided into X, X_test, y, and y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feature_scaler = StandardScaler()\n",
    "target_scaler = StandardScaler()\n",
    "\n",
    "X = feature_scaler.fit_transform(X)\n",
    "\n",
    "# y = y.reshape(-1, 1)\n",
    "# y = target_scaler.fit_transform(y)\n",
    "# y = y.ravel()\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Preparing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code standardizes the features and splits the dataset into training and testing sets:\n",
    "\n",
    "StandardScaler: Standardizes the feature matrix by removing the mean and scaling to unit variance.\n",
    "\n",
    "train_test_split: Splits the dataset into training (80%) and testing (20%) sets.\n",
    "\n",
    "The feature matrix X is transformed, and the dataset is divided into X, X_test, y, and y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feature_scaler = StandardScaler()\n",
    "target_scaler = StandardScaler()\n",
    "\n",
    "X = feature_scaler.fit_transform(X)\n",
    "\n",
    "# y = y.reshape(-1, 1)\n",
    "# y = target_scaler.fit_transform(y)\n",
    "# y = y.ravel()\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Initializing Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code initializes the parameters for the linear regression model:\n",
    "\n",
    "m, n: The shape of the feature matrix X, where m is the number of samples (442) and n is the number of features (10).\n",
    "\n",
    "w: The weight vector, initialized to zeros with shape [10,].\n",
    "\n",
    "b: The bias term, initialized to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = X.shape   # m = 442, n = 10\n",
    "w = np.zeros(n)  # Weight vector (shape: [10,])\n",
    "b = 0            # Bias term (scalar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5. Defining the Prediction Function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction function is given by:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, w, b):\n",
    "    return np.dot(X, w) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **6. Defining the Cost Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, y, w, b):\n",
    "    m = len(y)\n",
    "    y_pred = predict(X, w, b)\n",
    "    cost = (1 / (2 * m)) * np.sum((y_pred - y) ** 2)\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **7. Computing the Gradients**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradients are computed to update the weights and bias during training. The partial derivatives of the cost function with respect to each weight and the bias are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradients(X, y, w, b):\n",
    "\n",
    "    m = len(y)\n",
    "    y_pred = predict(X, w, b)\n",
    "    error = y_pred - y\n",
    "\n",
    "    dw = (1 / m) * np.dot(X.T, error)\n",
    "    db = (1 / m) * np.sum(error)\n",
    "\n",
    "    return dw, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **8. Updating Parameters Using Gradient Descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(w, b, dw, db, learning_rate):\n",
    "\n",
    "    w = w - learning_rate * dw\n",
    "    b = b - learning_rate * db\n",
    "\n",
    "    return w, b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
